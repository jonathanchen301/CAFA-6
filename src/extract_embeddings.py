"""
Extract embeddings from protein sequences using ESM2-650M model
"""

import os

from transformers import EsmModel, EsmTokenizer
import torch
import numpy as np
import pandas as pd
import argparse
from tqdm import tqdm

def load_esm2_model(model_path: str, device: str = "cuda") -> tuple[EsmModel, EsmTokenizer, str]:
    """
    Load the ESM2-650M model and tokenizer from a given path.

    Args:
        model_path: Path to the ESM2-650M model
        device: Device to use for the model
    
    Returns:
        EsmModel: The ESM2-650M model
        EsmTokenizer: The ESM2-650M tokenizer
        device: Device used for the model
    """
    if device == "cuda" and not torch.cuda.is_available():
        print("CUDA not available, falling back to cpu")
        device = "cpu"

    model = EsmModel.from_pretrained(model_path)
    # tokenizer does not need to be moved
    tokenizer = EsmTokenizer.from_pretrained(model_path)

    model = model.to(device)
    model.eval()

    print("ESM2-650M Model Loaded Successfully on", device)

    return model, tokenizer, device

def extract_embeddings(sequences: list[str], model: EsmModel, tokenizer: EsmTokenizer, device: str = "cuda", batch_size: int = 32) -> np.ndarray:
    """
    Extract embeddings from protein sequences in batches using the ESM2-650M model.

    Args:
        sequences: List of protein sequences
        model: ESM2-650M Model
        tokenizer: ESM2-650M Tokenizer
        device: Device to use for the model
        batch_size: Batch size for the model

    Returns:
        np.ndarray: Array of embeddings of shape [num_sequences, hidden_size] with mean_pooled embeddings
    """

    if len(sequences) == 0:
        raise ValueError("No sequences provided for embedding extraction")
    all_embeddings = []

    for i in tqdm(range(0, len(sequences), batch_size)):
        batch_sequences = sequences[i:i+batch_size]
        
        encoded = tokenizer(
            batch_sequences,
            padding=True,
            truncation=True,
            return_tensors="pt"
        )

        input_ids = encoded["input_ids"].to(device)
        attention_mask = encoded["attention_mask"].to(device)

        with torch.no_grad():
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask
            )

        hidden_states = outputs.last_hidden_state

        sum_embeddings = (hidden_states * attention_mask.unsqueeze(-1)).sum(dim=1)
        sum_mask = attention_mask.sum(dim=1, keepdim=True).clamp(min=1)
        mean_pooled = sum_embeddings / sum_mask

        all_embeddings.append(mean_pooled.cpu().numpy())

    return np.vstack(all_embeddings)

def save_embeddings(protein_ids: list[str], embeddings: np.ndarray, output_path: str) -> None:
    """
    Save embeddings to a .npz file (which maps ids to embeddings)

    Args:
        protein_ids: List of protein ids
        embeddings: Array of embeddings of shape [num_sequences, hidden_size] with mean_pooled embeddings
        output_path: Path to save the embeddings
    """

    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    np.savez(output_path, ids=protein_ids, embeddings=embeddings)
    print(f"Saved {len(protein_ids)} embeddings to {output_path}")

def process_sequences_from_csv(csv_path: str, model_path: str, output_path: str, batch_size: int = 32, device: str = "cuda") -> None:
    """
    Load sequences from CSV file generated by process_sequences.py and extract embeddings using the ESM2-650M model.

    Args: 
        csv_path: Path to the CSV file generated by process_sequences.py
        model_path: Path to the ESM2-650M Model
        output_path: Path to save the embeddings
        batch_size: Batch size for the model
        device: Device to use for the model
    """

    # Validate input paths
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"CSV file not found: {csv_path}")
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model path not found: {model_path}")
    print("Loading sequences from CSV file...")
    df = pd.read_csv(csv_path)

    print("Loading ESM2-650M Model...")
    model, tokenizer, device = load_esm2_model(model_path, device)

    print("Extracting embeddings...")
    embeddings = extract_embeddings(df["sequence"].tolist(), model, tokenizer, device, batch_size)

    print("Saving embeddings...")
    protein_ids = df["id"].tolist()
    save_embeddings(protein_ids, embeddings, output_path)
    print("Embeddings saved successfully!")

def main():
    parser = argparse.ArgumentParser(
        description="Extract embeddings from protein sequences using ESM2-650M model and save to a .npz file"
    )

    parser.add_argument("--csv_path", type=str, required=True, help="Path to the CSV file generated by process_sequences.py")
    parser.add_argument("--model_path", type=str, required=True, help="Path to the ESM2-650M Model")
    parser.add_argument("--output_path", type=str, required=True, help="Path to save embeddings")
    parser.add_argument("--batch_size", type=int, required=False, default=32, help="Batch size for processing")
    parser.add_argument("--device", type=str, required=False, default="cuda", help="Device to use for processing")

    args = parser.parse_args()

    process_sequences_from_csv(args.csv_path, args.model_path, args.output_path, args.batch_size, args.device)

if __name__ == "__main__":
    main()